{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Affinity Answers.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOIVC2tzUEdNFWJgwM+gZUT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karynaur/degree-of-profanity/blob/main/Affinity_Answers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7pzcCyrKuk6"
      },
      "source": [
        "# Affinity Answers Task:\n",
        "\n",
        "1. Imagine there is a file full of Twitter tweets by various users and you are provided a set of words that indicates racial slurs. Write a program that can indicate the degree of profanity for each sentence in the file. Write in any programming language (preferably in Python)-make any assumptions, but remember to state them. Please place the code in GitHub with proper documentation and share."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpydG_5RK001"
      },
      "source": [
        "Assumptions made:      \n",
        "\n",
        "1. Data is provided in text files\n",
        "2. The data provided is just the tweet content and nothing else\n",
        "3. The slurs provided appear atleast once in the tweet dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbh-kvgbK71E"
      },
      "source": [
        "### Create Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzN43a0CKhli",
        "outputId": "4603fc9d-38ec-473f-faf2-30c6ad0af176"
      },
      "source": [
        "%%writefile tweets.txt\n",
        "Hey there! Heres a slur\n",
        "Bad words are not acceptable\n",
        "Slurs here, slurs there, slurs everywhere\n",
        "I am a bully!\n",
        "Heres a nice sentence\n",
        "Twitter is sometimes good!\n",
        "Twitter is honestly the worst\n",
        "And the list goes on and on with more RACE SLURS"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing tweets.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nKJ9THPM3jX",
        "outputId": "8bf36b86-da2b-4129-d7ea-e9ae0773936f"
      },
      "source": [
        "%%writefile slurs.txt\n",
        "bad, slur, bully, worst, race"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing slurs.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_CxObRSQEjl"
      },
      "source": [
        "with open('tweets.txt', 'r') as f:\n",
        "    sentences = f.readlines()\n",
        "\n",
        "with open('slurs.txt', 'r') as f:\n",
        "    slurs = f.read().split(',')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ7EUs54V_WQ"
      },
      "source": [
        "### Cleaning the data\n",
        "\n",
        "1. Make all text lower case\n",
        "2. Remove URL's and unicode characters\n",
        "3. Remove stopwords\n",
        "4. Lemmatization to group words based on root definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaDv-lCcTDSu"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import nltk.corpus\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('wordnet', quiet = True)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "\n",
        "def clean_data(text_list):\n",
        "    clean_text = []\n",
        "    for text in text_list:\n",
        "        # 1. Make all text lower case\n",
        "        text = text.lower()\n",
        "\n",
        "        # 2. Remove URL's and unicode characters\n",
        "        text = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", text)\n",
        "\n",
        "        # 3. Remove stopwords\n",
        "        text = \" \".join([word for word in text.split() if word not in (stop)])\n",
        "        \n",
        "        # 4. Lemmatization to group words based on root definition\n",
        "        text = \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "        clean_text.append(text)\n",
        "    return clean_text\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9UQtDomUHAw",
        "outputId": "cd3eaccd-15d6-4e37-9317-e6025577ebca"
      },
      "source": [
        "clean_sentence = clean_data(sentences)\n",
        "\n",
        "table = [[raw,clean] for raw,clean in zip(sentences, clean_sentence)]\n",
        "\n",
        "from tabulate import tabulate\n",
        "print(tabulate(table, headers = ['Raw data', 'Clean data']))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw data                                          Clean data\n",
            "------------------------------------------------  -------------------------\n",
            "Hey there! Heres a slur                           hey here slur\n",
            "Bad words are not acceptable                      bad word acceptable\n",
            "Slurs here, slurs there, slurs everywhere         slur slur slur everywhere\n",
            "I am a bully!                                     bully\n",
            "Heres a nice sentence                             here nice sentence\n",
            "Twitter is sometimes good!                        twitter sometimes good\n",
            "Twitter is honestly the worst                     twitter honestly worst\n",
            "And the list goes on and on with more RACE SLURS  list go race slur\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3-g-kUpZxNw",
        "outputId": "8011a0a2-f63e-45cf-b3ee-5fcfc594a83f"
      },
      "source": [
        "slurs = clean_data(slurs)\n",
        "slurs"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['bad', 'slur', 'bully', 'worst', 'race']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pRklfm4akdG"
      },
      "source": [
        "## Naive Approach\n",
        "Iterate though the text and find for words from the slurs provided"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJmSdvb3Q9yz",
        "outputId": "baf49597-293b-4451-991a-97fb3ebd4834"
      },
      "source": [
        "for i, sentence in enumerate(clean_sentence):\n",
        "    count = 0\n",
        "    original = sentences[i].splitlines()[0]\n",
        "    for word in sentence.split():\n",
        "        if word in slurs:\n",
        "            count += 1\n",
        "    print(f\"Degree of profanity of \\\"{original}\\\": {count/len(sentence.split()): 0.4f}\")\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Degree of profanity of \"Hey there! Heres a slur\":  0.3333\n",
            "Degree of profanity of \"Bad words are not acceptable\":  0.3333\n",
            "Degree of profanity of \"Slurs here, slurs there, slurs everywhere\":  0.7500\n",
            "Degree of profanity of \"I am a bully!\":  1.0000\n",
            "Degree of profanity of \"Heres a nice sentence\":  0.0000\n",
            "Degree of profanity of \"Twitter is sometimes good!\":  0.0000\n",
            "Degree of profanity of \"Twitter is honestly the worst\":  0.3333\n",
            "Degree of profanity of \"And the list goes on and on with more RACE SLURS\":  0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C3C-dsMSNUJ"
      },
      "source": [
        "## Using Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPpkCrtHF-p6",
        "outputId": "8747af83-ec02-4274-c264-639d5c0c670a"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# Get model and run it on our dataset\n",
        "model = Word2Vec([i.split() for i in clean_sentence], min_count=1)\n",
        "list(model.wv.vocab)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hey',\n",
              " 'here',\n",
              " 'slur',\n",
              " 'bad',\n",
              " 'word',\n",
              " 'acceptable',\n",
              " 'everywhere',\n",
              " 'bully',\n",
              " 'nice',\n",
              " 'sentence',\n",
              " 'twitter',\n",
              " 'sometimes',\n",
              " 'good',\n",
              " 'honestly',\n",
              " 'worst',\n",
              " 'list',\n",
              " 'go',\n",
              " 'race']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3B5S6lr_8Y3I"
      },
      "source": [
        "#### Absolute degree of profanity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aY1yq88iO9Kv",
        "outputId": "33c86647-431d-461e-b625-ec26df15d502"
      },
      "source": [
        "import numpy as np\n",
        "profanities = []\n",
        "\n",
        "# threshold similarity for calculative score\n",
        "threshold = 0.5\n",
        "print(f\"Absolute degree of profanity with a threshold profanity of {threshold}\\n\")\n",
        "for i, sentence in enumerate(clean_sentence):\n",
        "    total = 0\n",
        "    original = sentences[i].splitlines()[0]\n",
        "    for word in sentence.split():\n",
        "\n",
        "        # Check for similarity between words and slurs\n",
        "        for slur in slurs:\n",
        "            score = model.wv.similarity(slur.split()[0], word)\n",
        "            if score > threshold: total+=score\n",
        "    profanities.append(total)\n",
        "    print(f\"Degree of profanity of \\\"{original}\\\": {total: 0.4f}\")\n",
        "    "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute degree of profanity with a threshold profanity of 0.5\n",
            "\n",
            "Degree of profanity of \"Hey there! Heres a slur\":  1.0000\n",
            "Degree of profanity of \"Bad words are not acceptable\":  1.0000\n",
            "Degree of profanity of \"Slurs here, slurs there, slurs everywhere\":  3.0000\n",
            "Degree of profanity of \"I am a bully!\":  1.0000\n",
            "Degree of profanity of \"Heres a nice sentence\":  0.0000\n",
            "Degree of profanity of \"Twitter is sometimes good!\":  0.0000\n",
            "Degree of profanity of \"Twitter is honestly the worst\":  1.0000\n",
            "Degree of profanity of \"And the list goes on and on with more RACE SLURS\":  2.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjFa3Uoh8eLo"
      },
      "source": [
        "#### Relative degree of profanity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCdO-6exyhOF"
      },
      "source": [
        "from scipy.special import softmax\n",
        "\n",
        "# Take the softmax of individual profanity values to get relative profanity in our dataset\n",
        "profanities = softmax(profanities)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uAEKvGmyucb",
        "outputId": "3d89a1f1-9a7c-4c9e-d296-57824a2d686b"
      },
      "source": [
        "print(f\"Relative degree of profanity with a threshold of {threshold} in percentage\\n\")\n",
        "for ii, i in enumerate(sentences):\n",
        "    print(f\"Degree of profanity of \\\"{i.splitlines()[0]}\\\": {profanities[ii]*100: 0.2f}%\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relative degree of profanity with a threshold of 0.5 in percentage\n",
            "\n",
            "Degree of profanity of \"Hey there! Heres a slur\":  6.74%\n",
            "Degree of profanity of \"Bad words are not acceptable\":  6.74%\n",
            "Degree of profanity of \"Slurs here, slurs there, slurs everywhere\":  49.78%\n",
            "Degree of profanity of \"I am a bully!\":  6.74%\n",
            "Degree of profanity of \"Heres a nice sentence\":  2.48%\n",
            "Degree of profanity of \"Twitter is sometimes good!\":  2.48%\n",
            "Degree of profanity of \"Twitter is honestly the worst\":  6.74%\n",
            "Degree of profanity of \"And the list goes on and on with more RACE SLURS\":  18.31%\n"
          ]
        }
      ]
    }
  ]
}